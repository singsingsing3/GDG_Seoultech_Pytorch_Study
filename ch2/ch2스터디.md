## ğŸ” 1.Image Classification & Transfer Learning(VGG)

### âœï¸ 1.1 í•™ìŠµëœ VGGëª¨ë¸ ì‚¬ìš©
- ì „ì´í•™ìŠµê³¼ íŒŒì¸íŠœë‹ì„ êµ¬í˜„í•´ë³´ì
#### ğŸ’¬ 1.1.1 í•™ìŠµëœ VGG ë¶ˆëŸ¬ì˜¤ê¸°
```
import numpy as np
import json
from PIL import Image
import matplotlib.pyplot as plt
%matplotlib inline

import torch
import torchvision
from torchvision import models, transforms

print("PyTorch Version: ",torch.__version__)
print("Torchvision Version: ",torchvision.__version__)
```
í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ improtí•´ì¤€ë‹¤
```
use_pretrained = True
net=models.vgg16(pretrained=use_pretrained)
net.eval() # ëª¨ë¸ì„ í‰ê°€ ìƒíƒœë¡œ ë³€ê²½, dropoutì´ë‚˜ batch normalizationì„ í‰ê°€ ëª¨ë“œë¡œ ë³€ê²½
```
í•™ìŠµëœ VGGëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê³ ë‚˜ì„œ í‰ê°€ëª¨ë“œë¡œ ì „í™˜ í›„ ëª¨ë¸ ë‚´ë¶€ë¥¼ ì¶œë ¥í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤.
>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
...
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)

- in_featuresì™€ out_channelsì— ëŒ€í•œ ì´í•´ê°€ í•„ìš”í•˜ë‹¤
ì—¬ê¸°ì„œ featureëª¨ë“ˆì„ í†µê³¼í•œ ì´ë¯¸ì§€ëŠ” 512ì±„ë„, 7x7 sizeë¥¼ ê°–ê²Œ ë˜ë¯€ë¡œ (512,7,7) in_featuresê°€ 25088ì´ ë˜ëŠ” ê²ƒì´ë‹¤.
ì´í›„ ì „ê²°í•©ì¸µì„ ì§€ë‚˜ ì´ out_feature 1000ê°œë¡œ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.

#### ğŸ’¬ 1.1.2 ì „ì²˜ë¦¬ Class ì‘ì„±
```
class BaseTransform():
    """
    Attributes
    ------------
    resize: int
        í¬ê¸° ë³€ê²½ ì „ì˜ í™”ìƒí¬ê¸°
    mean: (R, G, B)
        ê° ìƒ‰ìƒ ì±„ë„ì˜ í‰ê· ê°’
    std: (R, G, B)
        ê° ìƒ‰ìƒ ì±„ë„ì˜ í‘œì¤€í¸ì°¨
    """
    
    def __init__(self,resize,mean,std):
        self.base_transform=transforms.Compose([
            transforms.Resize(resize),
            transforms.CenterCrop(resize),
            transforms.ToTensor(),
            transforms.Normalize(mean,std)
        ])
    
    def __call__(self,img):
        return self.base_transform(img)
```
- Composeë¥¼ ê±°ì³ ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬ ì‹œí‚¨ë‹¤
-> ì´ë¯¸ì§€ì˜ ì§§ì€ ë³€ì„ `resize`ë¡œ ì„¤ì •
-> ì´ë¯¸ì§€ ì¤‘ì•™ì„ resize x resize ë¡œ ì˜ë¼ë‚´ê¸°
-> ì´ë¯¸ì§€ë¥¼ tensorë¡œ ë³€í™˜
-> ì´ë¯¸ì§€ë¥¼ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¡œ ì •ê·œí™”
- __call__ í•¨ìˆ˜ëŠ” í´ë˜ìŠ¤ë¥¼ í•¨ìˆ˜ì²˜ëŸ¼ í˜¸ì¶œ í–ˆì„ ë•Œ í˜¸ì¶œë˜ëŠ” í•¨ìˆ˜ì´ë‹¤
```
# í™”ìƒ ì „ì²˜ë¦¬ í™•ì¸í•´ë³´ê¸°

image_file_path = './data/goldenretriever-3724972_640.jpg'
img=Image.open(image_file_path)

plt.imshow(img)
plt.show()

resize=224
mean=(0.485,0.456,0.406)
std=(0.229,0.224,0.225)
transform=BaseTransform(resize,mean,std)
img_transformed=transform(img)

img_transformed=img_transformed.numpy().transpose((1,2,0)) # í…ì„œë¥¼ numpyë¡œ ë³€í™˜í•˜ê³  ì¶•ì„ ë³€í™˜(PIL ì´ë¯¸ì§€ëŠ” heigh*width*channel, í…ì„œëŠ” channel*height*width)
img_transformed=np.clip(img_transformed,0,1) # ì´ë¯¸ì§€ í”½ì…€ ê°’ì„ 0~1ë¡œ ì •ê·œí™”

plt.imshow(img_transformed)
plt.show()

```
- ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì™€ë³´ì
- ì´ë•Œ ì´ë¯¸ì§€ í…ì„œë¥¼ numpy í˜•ì‹ì— ë§ê²Œ transpose ì‹œí‚¤ê³  ì‹œê°í™” í•´ë³¸ë‹¤

#### ğŸ’¬ 1.1.3 í›„ì²˜ë¦¬ Class ìƒì„±
- ëª¨ë¸ì˜ 1000ê°œì˜ class ì¶œë ¥ì„ ë¼ë²¨ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤ë¥¼ ë§Œë“¤ì–´ë³´ì
```
# ë¼ë²¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì‚¬ì „í˜• ë³€ìˆ˜ ìƒì„±
ILSVRC_class_index=json.load(open('./data/imagenet_class_index.json','r'))
ILSVRC_class_index
```
- ë¼ë²¨ ì •ë³´ëŠ” í•´ë‹¹ jsoníŒŒì¼ì— ë‹´ê²¨ìˆë‹¤.
>{'0': ['n01440764', 'tench'],
 '1': ['n01443537', 'goldfish'],
 '2': ['n01484850', 'great_white_shark'],
 '3': ['n01491361', 'tiger_shark'],
 '4': ['n01494475', 'hammerhead'],
 '5': ['n01496331', 'electric_ray'],
 '6': ['n01498041', 'stingray'],


ã…£
 
 ```
 # ì˜ˆì¸¡ í›„ í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ë¼ë²¨ì„ ì˜ˆì¸¡ ê²°ê³¼ë¡œ ì¶œë ¥í•˜ëŠ” í•¨ìˆ˜
class ILSVRCPredictor():
    """
    ISLVRCë°ì´í„° ëª¨ë¸ì˜ ì¶œë ¥ì—ì„œ ë¼ë²¨ì„ êµ¬í•œë‹¤.

    Attributes
    ------------
    class_index: dictionary
        í‚¤ëŠ” ë¼ë²¨, ê°’ì€ ë¼ë²¨ ì´ë¦„
    """

    def __init__(self,class_index):
        self.class_inedx=class_index
    
    def predict_max(self,out):
        """
        í™•ë¥ ì´ ê°€ì¥ ë†’ì€ ILSVRC ë¼ë²¨ì„ ì˜ˆì¸¡í•œë‹¤.

        Parameters
        ------------
        out: torch.Size([1, 1000])
            Netì˜ ì¶œë ¥

        Returns
        ------------
        predicted_label_name: str
            ì˜ˆì¸¡í•œ ë¼ë²¨ ì´ë¦„
        """
        maxid=np.argmax(out.detach().numpy()) #ë„˜íŒŒì´ ë³€í™˜ì„ ìœ„í•´ detach()ì‚¬ìš© í›„ numpy ë³€í™˜ -> ê°€ì¥ ë†’ì€ ê°’ì˜ ì¸ë±ìŠ¤ ì¶”ì¶œ
        predicted_label_name=self.class_inedx[str(maxid)][1] 

        return predicted_label_name

```
- outì€ tensor ê°’ì„ ê°€ì§€ë¯€ë¡œ detach()ë¥¼ ì´ìš©í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ì—ì„œ ë¶„ë¦¬í›„ numpyë¡œ ë³€í™˜ì‹œì¼œ numpyì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤

#### ğŸ’¬ 1.1.4 ëª¨ë¸ ì˜ˆì¸¡
```
ILSVRC_class_index=json.load(open('./data/imagenet_class_index.json','r'))
predictor=ILSVRCPredictor(ILSVRC_class_index) # predictí•˜ëŠ” í´ë˜ìŠ¤ ìƒì„±


imgage_file_path='./data/goldenretriever-3724972_640.jpg'
img=Image.open(image_file_path)

transform=BaseTransform(resize,mean,std)
img_transformed=transform(img) # ìœ„ì—ì„œ ì„ ì–¸í•œ ì „ì²˜ë¦¬ í´ë˜ìŠ¤ë¡œ ì „ì²˜ë¦¬
inputs=img_transformed.unsqueeze_(0) # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (ë°°ì¹˜ ìˆ˜ , ì»¬ëŸ¬, ë†’ì´ ë„ˆë¹„)

out=net(inputs)
result=predictor.predict_max(out) # ëª¨ë¸ì˜ ì¶œë ¥ì˜ ê²°ê³¼ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” í•¨ìˆ˜ë¡œ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥

print("ì…ë ¥ í™”ìƒì˜ ì˜ˆì¸¡ ê²°ê³¼: ",result)
```
>ì…ë ¥ í™”ìƒì˜ ì˜ˆì¸¡ ê²°ê³¼:  golden_retriever

- `img_transformed.unsqueeze_(0)`ì„ ì´ìš©í•˜ì—¬ ì´ë¯¸ì§€ì˜ ë°°ì¹˜ ì°¨ì›ì„ ì¶”ê°€ì‹œí‚¨ë‹¤
-> VGG ëª¨ë¸ì˜ inputê°’ì€ (ë°°ì¹˜ ìˆ˜, ì±„ë„, height, width)ì´ë¯€ë¡œ ë°°ì¹˜ìˆ˜ ì°¨ì›ì„ ê°–ê²Œë” ì´ë¯¸ì§€ë¥¼ ì°¨ì›ì„ í™•ì¥ì‹œì¼°ë‹¤.

- ì´ë¡œì¨ VGG ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ ê°„ë‹¨í•œ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ í•´ë³´ì•˜ë‹¤.

### âœï¸ 1.2 ë”¥ëŸ¬ë‹  êµ¬í˜„ íë¦„

#### 1. ì „ì²˜ë¦¬, í›„ì²˜ë¦¬, ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ì˜ ì…ì¶œë ¥ í™•ì¸
-> ì „ì²˜ë¦¬ë¥¼ ì–´ë–»ê²Œ í•  ê²ƒì¸ê°€, í›„ì²˜ë¦¬ëŠ” ì–´ë–»ê²Œ í•  ê²ƒì¸ê°€, ì–´ë–¤ ëª¨ë¸ì„ ì“¸ ê²ƒì´ê³  ê·¸ ëª¨ë¸ì˜ ê³„ì¸µì€ ì–´ë–»ê²Œ êµ¬í˜„ë˜ì–´ ìˆëŠ”ê°€
#### 2. ë°ì´í„°ì…‹ ì‘ì„±
-> train set, val_setì— ëŒ€í•œ Dataset ì‘ì„±, Dataset Calss ì‘ì„±

#### 3. ë°ì´í„° ë¡œë” ì‘ì„±
-> data setì„ ì–´ë–»ê²Œ ê°€ì ¸ì˜¬ ê²ƒì¸ì§€ ì‘ì„±, DataLoader Class ì‘ì„±

#### 4. ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì‘ì„±
-> ëª¨ë¸ì„ ì–´ë–»ê²Œ ê°€ì ¸ì˜¬ ê²ƒì¸ê°€, ì–´ë–»ê²Œ íŠœë‹í•  ê²ƒì¸ê°€

#### 5. ìˆœì „íŒŒ ì •ì˜
-> 2ì¥ì—ì„œ ë‹¤ë£° ì˜ˆì •

#### 6. ì†ì‹¤í•¨ìˆ˜ ì •ì˜
-> ì–´ë–¤ ì†ì‹¤í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ê²ƒì¸ê°€

#### 7. ìµœì í™” ê¸°ë²• ì„¤ì •
-> ì–´ë–¤ Optimizationì„ ì‚¬ìš©í•  ê²ƒì¸ê°€

#### 8. í•™ìŠµ/ê²€ì¦
-> train & validë¡œ ëª¨ë¸ ì„±ëŠ¥ í™•ì¸

#### 9. í…ŒìŠ¤íŠ¸
-> test setìœ¼ë¡œ ëª¨ë¸ ìµœì¢… ì„±ëŠ¥ í™•ì¸

### âœï¸ 1.3 ì „ì´í•™ìŠµ êµ¬í˜„
- í•™ìŠµëœ ëª¨ë¸ì„ ê¸°ë°˜ìœ¼ë¡œ `ìµœì¢… ì¶œë ¥ì¸µ ë¶€ê·¼`ì„ own dataì— ë§ê²Œ ì¡°ì ˆí•˜ì—¬ í•™ìŠµí•˜ëŠ” ê¸°ë²•
- ì…ë ¥ì¸µê¹Œì§€ ë‹¤ì‹œ í•™ìŠµì‹œí‚¤ëŠ” `íŒŒì¸íŠœë‹` ê¸°ë²•ì€ ë‹¤ìŒ ì ˆì— ì•Œì•„ë³¸ë‹¤
#### 1. ì „ì²˜ë¦¬, í›„ì²˜ë¦¬, ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ì˜ ì…ì¶œë ¥ í™•ì¸
- VGG16ì„ ê°€ì ¸ì˜¤ê³ , ì „ì²˜ë¦¬ë¡œ ì •ê·œí™” ,ì¦ê°• ì‚¬ìš©, í›„ì²˜ë¦¬ë¡œ labeling í•œë‹¤. 
- í•„ìš”í•œ libë“¤ì„ importí•´ì„œ ê°€ì ¸ì˜¨ë‹¤


```
import glob
import os.path as osp
import random
import numpy as np
import json
from PIL import Image
from tqdm import tqdm
import os
import matplotlib.pyplot as plt
%matplotlib inline

import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torchvision
from torchvision import models, transforms

torch.manual_seed(1234)
np.random.seed(1234)
random.seed(1234)

os.getcwd()
```

#### 2. ë°ì´í„°ì…‹ ì‘ì„±
```
class ImageTransform():
    def __init__(self, resize, mean, std):
        self.data_transform = {
            'train': transforms.Compose([
                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Normalize(mean, std)
            ]),
            'val': transforms.Compose([
                transforms.Resize(resize),
                transforms.CenterCrop(resize),
                transforms.ToTensor(),
                transforms.Normalize(mean, std)
            ])
        }
    
    def __call__(self, img, phase='train'):
        """ phase: 'train' or 'val' """
        return self.data_transform[phase](img)
```
- `í›ˆë ¨ì‹œ`ì—ëŠ” data augmentationì„ ì´ìš©í•˜ì—¬ dataë¥¼ ì¦ê°•ì‹œí‚¨ë‹¤.
```
# í›ˆë ¨ ì‹œ í™”ìƒ ì „ì²˜ë¦¬ ë™ì‘ í™•ì¸
# ì‹¤í–‰í•  ë•Œë§ˆë‹¤ ì²˜ë¦¬ ê²°ê³¼ í™”ìƒì´ ë°”ë€œì„ ì•Œ ìˆ˜ ìˆìŒ

img_file_path='./data/goldenretriever-3724972_640.jpg'
img=Image.open(img_file_path) # h,w,c ìˆœì„œ
print(img.size)
plt.imshow(img)
plt.show() # ì›ë³¸ íŒŒì¼ í‘œì‹œ

size=224
mean=(0.485, 0.456, 0.406)
std=(0.229, 0.224, 0.225)

transform=ImageTransform(size, mean, std)
img_transformed=transform(img, phase="train") # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€

img_transformed=img_transformed.numpy().transpose((1, 2, 0)) # c,h,w ìˆœì„œë¡œ ë³€í™˜
img_transformed=np.clip(img_transformed, 0, 1)
plt.imshow(img_transformed)
plt.show() # ì „ì²˜ë¦¬ëœ íŒŒì¼ í‘œì‹œ
```
- augmentationì´ ì˜ ì´ë£¨ì–´ì¡ŒëŠ”ì§€ í™•ì¸í•´ë³¸ë‹¤
- `transform=ImageTransform(size, mean, std)` í´ë˜ìŠ¤ë¥¼ transform ë³€ìˆ˜ì— ì €ì¥í•œë‹¤
-> ì´í›„ ì´ ë³€ìˆ˜ë¥¼ í•¨ìˆ˜ì²˜ëŸ¼ í˜¸ì¶œí•˜ì—¬ `transform(img, phase="train")` `__call__ ` í´ë˜ìŠ¤ ë‚´ë¶€ì˜ í•¨ìˆ˜ returnê°’`self.data_transform[phase](img)`ë¥¼ ì‹¤í–‰ì‹œí‚¤ê³  ì´ ì½”ë“œëŠ” ë‹¤ì‹œ 
`  self.data_transform `ì„ ì‚¬ìš©ìê°€ ì…ë ¥í•œ `phase`ì— ë§ì¶° ì‹¤í–‰ì‹œí‚¨ë‹¤

```
# ê°œë¯¸ì™€ ë²Œì´ ë‹´ê¸´ í™”ìƒ íŒŒì¼ìœ¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ ì‘ì„±

def make_datapath_list(phase="train"):
    """
    ë°ì´í„°ì˜ ê²½ë¡œë¥¼ ì§€ì •í•œ ë¦¬ìŠ¤íŠ¸ ì‘ì„±

    Parameters
    ----------
    phase : 'train' or 'val'
        í›ˆë ¨ ë°ì´í„° ë˜ëŠ” ê²€ì¦ ë°ì´í„°ë¥¼ ì§€ì •

    Returns
    -------
    path_list : list
        ë°ì´í„°ì˜ ê²½ë¡œë¥¼ ì €ì¥í•œ ë¦¬ìŠ¤íŠ¸
    """
    rootpath = "./data/hymenoptera_data/"
    target_path = osp.join(rootpath+phase+'/**/*.jpg') # í˜„ì¬ í´ë”ì˜ í•˜ìœ„ í´ë”ê¹Œì§€ ê²€ìƒ‰í•˜ì—¬ jpg íŒŒì¼ì„ ì°¾ìŒ
    print(target_path)

    path_list=[]

    for path in glob.glob(target_path):
        path_list.append(path)
    
    return path_list


triand_list=make_datapath_list(phase="train")
val_list=make_datapath_list(phase="val")

triand_list
```
- ê°œë¯¸ì™€ ë²Œì„ classifyí•˜ê¸° ìœ„í•´ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•œë‹¤
>['./data/hymenoptera_data/train\\ants\\0013035.jpg',
 './data/hymenoptera_data/train\\ants\\1030023514_aad5c608f9.jpg',
 './data/hymenoptera_data/train\\ants\\1095476100_3906d8afde.jp
 

```
class HymenopteraDataset(data.Dataset):

    def __init__(self, file_list,transform=None,phase='train'):
        self.file_list=file_list
        self.transform=transform
        self.phase=phase
    
    def __len__(self):
        return len(self.file_list)
    
    def __getitem__(self,index):
        
        img_path=self.file_list[index]
        img=Image.open(img_path)

        img_transformed=self.transform(img,self.phase)

        if self.phase=='train':
            label=img_path[30:34] # íŒŒì¼ ê²½ë¡œì—ì„œ ë¼ë²¨ì„ ì¶”ì¶œ
        elif self.phase=='val':
            label=img_path[28:32]
        
        if label=="ants":
            label=0
        elif label=="bees":
            label=1
        
        return img_transformed,label

train_dataset=HymenopteraDataset(file_list=triand_list,transform=ImageTransform(size,mean,std),phase='train')
val_dataset=HymenopteraDataset(file_list=val_list,transform=ImageTransform(size,mean,std),phase='val')

index=0
print(train_dataset.__getitem__(index)[0].size())
print(train_dataset.__getitem__(index)[1])
        
```
 - Dataset classë¥¼ ì‘ì„±í•˜ì—¬ train data setê°€ valid data setì„ ë§Œë“ ë‹¤.
 - ì´ë¯¸ì§€ê°€ ê°œë¯¸=0, ë²Œ=1ë¡œ ì§€ì •í•œë‹¤
 -> ì´ë•Œ labelì€ íŒŒì¼ ê²½ë¡œì—ì„œ ë¼ë²¨ì„ ì¶”ì¶œí•´ë‚¸ë‹¤. ` label=img_path[30:34]`
 
#### 3. ë°ì´í„° ë¡œë” ì‘ì„± 
```
 batch_size=32

train_dataloader=torch.utils.data.DataLoader(
    train_dataset,batch_size=batch_size,shuffle=True
)

val_dataloader=torch.utils.data.DataLoader(
    val_dataset,batch_size=batch_size,shuffle=False
)

dataloaders_dict={
    'train':train_dataloader,
    'val':val_dataloader
}

batch_iterator=iter(dataloaders_dict['train'])
inputs,labels=next(batch_iterator)

print(inputs.size())
print(labels) # 32ê°œì˜ ë¼ë²¨ì´ ì¶œë ¥ë¨
```
- ë‹¤ ë§Œë“  data setì„ ì–´ë–»ê²Œ ê°€ì ¸ì˜¬ ê²ƒì¸ì§€ ì„ ì–¸í•œë‹¤.
- train dataëŠ” dataë¥¼ ê³¨ê³ ë£¨ ê°€ì ¸ì˜¤ê°€ ìœ„í•´ shuffleí•´ì„œ ê°€ì ¸ì˜¨ë‹¤.
>torch.Size([32, 3, 224, 224])
tensor([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,
        0, 0, 1, 1, 0, 1, 0, 0])

- ë°°ì¹˜32, ì±„ë„3(RGB), 224 x 224 ì‚¬ì´ì¦ˆì˜ ì´ë¯¸ì§€ì„ì„ ì•Œ ìˆ˜ ìˆê³  ê°ê° ì–´ë–¤ ë¼ë²¨ì„ ê°–ëŠ”ì§€ ì•Œ ìˆ˜ ìˆë‹¤.
#### 4. ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì‘ì„±

```
use_pretrained=True
net=models.vgg16(pretrained=use_pretrained)

print(net.classifier[6]) # Linear(in_features=4096, out_features=1000, bias=True) -> out featureë¥¼ 2ê°œë¡œ ë³€ê²½í•´ì•¼í•¨

net.classifier[6]=nn.Linear(in_features=4096,out_features=2)
print(net.classifier[6])

net.train()
print('í›ˆë ¨ ì‹œì‘')

```
- í•™ìŠµëœ VGG16ì„ ê°€ì ¸ì˜¨ë‹¤.
- ì´ë•Œ ìµœì¢… ì¶œë ¥ì¸µ `classifier[6]` ë¶€ë¶„ì„ ìš°ë¦¬ì˜ dataì— ë§ê²Œ out feature = 2ë¡œ ìˆ˜ì •í•œë‹¤(ê°œë¯¸, ë²Œ)
- ìµœì¢… ì¶œë ¥ì¸µì„ ìˆ˜ì • í›„ í•™ìŠµ ì‹œí‚¨ë‹¤.
>
VGG16ì˜ classifier ë¶€ë¶„ì€ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ì´ë‹¤.
classifier[0] : Linear(25088, 4096)
classifier[1] : ReLU()
classifier[2] : Dropout(p=0.5)
classifier[3] : Linear(4096, 4096)
classifier[4] : ReLU()
classifier[5] : Dropout(p=0.5)
classifier[6] : Linear(4096, 1000)

Convolutional layer ë¶€ë¶„
Classifier ë¶€ë¶„ìœ¼ë¡œ êµ¬ì„±

ì§€ê¸ˆ ìš°ë¦¬ê°€ í•˜ê³  ìˆëŠ” ê²ƒì€ ìµœì¢… ë§ˆì§€ë§‰ ì¶œë ¥ì¸µì„ 2ê°œë¡œ ë³€ê²½í•˜ê³  ì¶œë ¥ì¸µì„ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒ
"""


#### 6. ì†ì‹¤í•¨ìˆ˜ ì •ì˜
```
 criterion=nn.CrossEntropyLoss() # ì†ì‹¤í•¨ìˆ˜ ì„¤ì •
```
- ë¶„ë¥˜ ë¬¸ì œì´ë¯€ë¡œ Corss Entropyë¥¼ ì‚¬ìš©í•œë‹¤.

#### 7. ìµœì í™” ê¸°ë²• ì„¤ì •
```
params_to_update=[]

update_param_names=["classifier.6.weight","classifier.6.bias"]

for name, param in net.named_parameters():
    if name in update_param_names:
        param.requires_grad=True
        params_to_update.append(param)
        print(name)
    else:
        param.requires_grad=False

print('-----------------')
print(params_to_update)
```
- classifierì˜ 6ë²ˆì§¸ layerì˜ ê°€ì¤‘ì¹˜ì™€ í¸í•­ì„ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ í•´ë‹¹ ë¶€ë¶„ë§Œ `param.requires_grad=True`ë¡œ ì„¤ì •í•˜ê³  ë‚˜ë¨¸ì§€ ë¶€ë¶„ì€ freeze ì‹œí‚¨ë‹¤.
```
optimizer=optim.SGD(params=params_to_update,lr=0.001,momentum=0.9)
```
- SGDë¥¼ ì‚¬ìš©í•œë‹¤.
#### 8. í•™ìŠµ/ê²€ì¦
```
def train_model(net,dataloaders_dict,criterion,optimizer,num_epochs):
    for epoch in range(num_epochs):
        print(f'Epoch {epoch+1}/{num_epochs}')
        print('-----------------')

        for phase in ['train','val']:
            if phase=='train':
                net.train()
            else:
                net.eval()
            epoch_loss=0.0
            epoch_corrects=0

            if(epoch==0) and (phase=='train'):
                continue

            for inputs,labels in tqdm(dataloaders_dict[phase]):
                optimizer.zero_grad()

                with torch.set_grad_enabled(phase=='train'):
                    outputs=net(inputs)
                    loss=criterion(outputs,labels)
                    _,preds=torch.max(outputs,1) # ìµœëŒ“ê°’ê³¼  ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜ -> ìµœëŒ“ê°’ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ, 1ì€ í–‰ì„ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ“ê°’ ì°¾ìœ¼ë¼ëŠ” ëœ»

                    if phase=='train':
                        loss.backward()
                        optimizer.step()

                    epoch_loss+=loss.item()*inputs.size(0)
                    epoch_corrects+=torch.sum(preds==labels.data)
        
        epoch_loss=epoch_loss/len(dataloaders_dict[phase].dataset)
        epoch_acc=epoch_corrects.double()/len(dataloaders_dict[phase].dataset)

        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')
                

```
- trainì¼ ë•Œ backwardë¥¼ ì§„í–‰ì‹œí‚¤ê³  í•™ìŠµì‹œí‚¨ë‹¤.
- evalì¼ ë•ŒëŠ” í•™ìŠµí•˜ì§€ ì•ŠëŠ”ë‹¤.
- `_,preds=torch.max(outputs,1)` dim=1 ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ ê°’ì„ ë½‘ì•„ë‚´ì–´ ì˜ˆì¸¡ì„ ì‹¤ì‹œí•œë‹¤.
```
num_epochs=2
train_model(net,dataloaders_dict,criterion,optimizer,num_epochs)
```
- ì—í­ì„ 2ë¡œ ì„¤ì •í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí–ˆë‹¤.
```
Epoch 1/2
-----------------
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:41<00:00,  8.28s/it]
val Loss: 0.7191 Acc: 0.4967
Epoch 2/2
-----------------
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:02<00:00,  7.86s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:46<00:00,  9.29s/it]
val Loss: 0.1726 Acc: 0.9608
```

### âœï¸ 1.4 íŒŒì¸íŠœë‹ êµ¬í˜„
- 1.3ì—ì„œëŠ” ì¶œë ¥ì¸µë§Œ í•™ìŠµì‹œì¼°ì§€ë§Œ ì´ë²ˆì—” feature ê³„ì¸µê³¼ ë‹¤ë¥¸ classify ê³„ì¸µë“¤ë„ í•™ìŠµì‹œì¼œë³´ì

```
import numpy as np
import random

import torch
import torch.nn as nn
import torch.optim as optim

from torchvision import models

from tqdm import tqdm

torch.manual_seed(1234)
np.random.seed(1234)
random.seed(1234)
```
- í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ ê°€ì ¸ì˜¨ë‹¤.
- seedë¥¼ ê³ ì •ì‹œì¼œ ì´í›„ì—ë„ ê°™ì€ ê°’ì„ ì–»ë„ë¡ ì¡°ì •í•œë‹¤.

#### ë°ì´í„° ì…‹ê³¼ ë¡œë” ì‘ì„±
```
from utils.dataloader_image_classification import ImageTransform, make_datapath_list,HymenopteraDataset

train_list = make_datapath_list(phase="train")
val_list = make_datapath_list(phase="val")

size=224
mean=(0.485,0.456,0.406)
std=(0.229,0.224,0.225)
train_dataset = HymenopteraDataset(
    file_list=train_list, transform=ImageTransform(size,mean,std), phase='train')

val_dataset = HymenopteraDataset(
    file_list=val_list, transform=ImageTransform(size,mean,std), phase='val')

bathc_size = 32
train_dataloader = torch.utils.data.DataLoader(
    train_dataset, batch_size=bathc_size, shuffle=True)

val_dataloader = torch.utils.data.DataLoader(
    val_dataset, batch_size=bathc_size, shuffle=False)

dataloaders_dict = {"train": train_dataloader, "val": val_dataloader}
```
- 1.3 ì ˆì—ì„œ ì„¤ëª…í–ˆìœ¼ë¯€ë¡œ ìì„¸í•œ ì„¤ëª…ì€ ìƒëµí•˜ê² ë‹¤.
#### ë„¤íŠ¸ì›Œí¬ ëª¨ë¸ ì‘ì„±, ì†ì‹¤í•¨ìˆ˜ ì •ì˜
```
use_pretrained = True
net = models.vgg16(pretrained=use_pretrained)

net.classifier[6]=nn.Linear(in_features=4096,out_features=2)

net.train()

print('ë„¤íŠ¸ì›Œí¬ ì„¤ì • ì™„ë£Œ')
```
```
criterion = nn.CrossEntropyLoss()
```
#### ìµœì í™” ë°©ë²• ì„¤ì •
```
params_to_update_1 = [] # CNNì¸µ
params_to_update_2 = [] # ì¶œë ¥ì¸µê³¼ ê°€ê¹Œìš´ ì¸µ
params_to_update_3 = [] # ì¶œë ¥ì¸µ

update_param_names_1 = ["features"]
update_param_names_2 = ["classifier.0.weight", "classifier.0.bias", "classifier.3.weight", "classifier.3.bias"]
update_param_names_3 = ["classifier.6.weight", "classifier.6.bias"]

for name, param in net.named_parameters():
    if update_param_names_1[0] in name:
        param.requires_grad = True
        params_to_update_1.append(param)
        print("params_to_update_1ì— ì €ì¥:", name)
    
    elif name in update_param_names_2:
        param.requires_grad = True
        params_to_update_2.append(param)
        print("params_to_update_2ì— ì €ì¥:", name)
    
    elif name in update_param_names_3:
        param.requires_grad = True
        params_to_update_3.append(param)
        print("params_to_update_3ì— ì €ì¥:", name)
    
    else:
        param.requires_grad = False
        print("ê²½ì‚¬ ê³„ì‚° ì—†ìŒ:", name)
```
- ê° layerë§ˆë‹¤ êµ¬ë¶„í•˜ì—¬ listì— ë‹´ëŠ”ë‹¤.
- ëª©í‘œ layerë¥¼`param.requires_grad = True`ë¡œ ì„¤ì •í•˜ì—¬ í•™ìŠµ ì¤€ë¹„ë¥¼ í•œë‹¤.

```
optimizer=optim.SGD([
    {'params':params_to_update_1, 'lr':1e-4},
    {'params':params_to_update_2, 'lr':5e-4},
    {'params':params_to_update_3, 'lr':1e-3}
], momentum=0.9)
```
- optimzierë¡œ SGDë¥¼ ì‚¬ìš©í•˜ê³ . í•™ìŠµì‹œí‚¤ê³ ì í•˜ëŠ” ê³„ì¸µì— ë”°ë¼ ë‹¤ë¥¸ learning rateë¥¼ ì ìš©ì‹œí‚¨ë‹¤.

- ì´ë¡œì¨ ì´ì „ê³¼ ë‹¬ë¦¬ ì¶œë ¥ì¸µë§Œ í•™ìŠµì‹œí‚¤ëŠ” ê²ƒì´ ì•„ë‹Œ ëª¨ë¸ì˜ ëª¨ë“  ì¸µì„ í•™ìŠµì‹œí‚¨ë‹¤.

#### ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦
```
def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    print("ì‚¬ìš© ì¥ì¹˜: ", device)

    net.to(device)

    torch.backends.cudnn.benchmark = True # ê³„ì‚°ì´ ì¼ì •í•˜ë‹¤ë©´ ê³ ì†í™” ì§„í–‰

    for epoch in range(num_epochs):
        print('Epoch {}/{}'.format(epoch+1, num_epochs))
        print('-' * 10)

        for phase in ['train', 'val']:
            if phase == 'train':
                net.train()
            else:
                net.eval()
            
            epoch_loss=0.0
            epoch_corrects=0

            if (epoch == 0) and (phase == 'train'):
                continue
            
            #ë¯¸ë‹ˆë°°ì¹˜ë¥¼ êº¼ë‚´ ë£¨í”„ ì‹¤í–‰
            for inputs, labels in tqdm(dataloaders_dict[phase]):
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()
            
            with torch.set_grad_enabled(phase == 'train'):
                outputs = net(inputs)
                loss = criterion(outputs, labels)
                _, preds = torch.max(outputs, 1) # dim=1ê¸°ì¤€

                if phase == 'train':
                    loss.backward()
                    optimizer.step()
                
                epoch_loss += loss.item() * inputs.size(0)
                epoch_corrects += torch.sum(preds == labels.data)
            
            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)
            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)

            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))
```
- `torch.backends.cudnn.benchmark = True` ì…ë ¥ í¬ê¸°ê°€ ì¼ê´€ì ì´ê³  GPUì—ì„œ í•™ìŠµí•  ë•Œ í•™ìŠµì„ ê³ ì†í™” ì‹œí‚¤ê¸° ìœ„í•´ ì‚¬ìš©í–ˆë‹¤.
```
num_epochs=2
train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)
```
- 2ì—í­ë§Œ í•™ìŠµì‹œì¼°ë‹¤.
#### ëª¨ë¸ save & load
```
# íŒŒë¼ë¯¸í„° ì €ì¥
save_path='./weights_fine_tuning.pth'
torch.save(net.state_dict(), save_path)
```
```
# íŒŒë¼ë¯¸í„° ë¡œë“œ
load_path='./weights_fine_tuning.pth'
load_weights = torch.load(load_path)
net.load_state_dict(load_weights)

# GPUì— ì €ì¥ëœ ê°€ì¤‘ì¹˜ë¥¼ CPUì— ë¡œë“œí•˜ëŠ” ê²½ìš°
load_weights = torch.load(load_path, map_location={'cuda:0':'cpu'})
net.load_state_dict(load_weights)
```
- ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì •ë³´ë“¤ì„ ë”•ì…”ë„ˆë¦¬ í˜•ì‹ìœ¼ë¡œ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜¨ë‹¤.
- ì´ë¡œì¨ ì´ë¯¸ì§€ë¥¼ classifyí•˜ëŠ” íŒŒì´í”„ë¼ì¸ì„ êµ¬í˜„í•´ë³´ì•˜ìœ¼ë©° ì „ì´í•™ìŠµê³¼ íŒŒì¸íŠœë‹ì„ êµ¬í˜„í•´ë´¤ë‹¤.
- ì¶”ê°€ì ìœ¼ë¡œ ì•Œì•„ë³¸ ê²°ê³¼ íŒŒì¸íŠœë‹ ê³¼ì •ì—ì„œ ë³¸ë¬¸ì—ì„œëŠ” ì „ì²´ ê³„ì¸µì„ í•™ìŠµì‹œì¼°ì§€ë§Œ ì¼ë¶€ í•„ìš”í•œ ê³„ì¸µë§Œ í•™ìŠµì‹œí‚¤ê³  ë‚˜ë¨¸ì§€ëŠ” freezeì‹œì¼œì„œ ìƒˆë¡­ê²Œ í•™ìŠµì‹œí‚¤ëŠ” íŒŒì¸íŠœë‹ ê¸°ë²•ë„ ìˆë‹¤.
ì¦‰, ìƒí™©ì— ë§ê²Œ í•„ìš”í•œ ê³„ì¸µì„ í•™ìŠµì‹œí‚¤ëŠ” ëŠ¥ë ¥ì´ í•„ìš”í•˜ë‹¤.
